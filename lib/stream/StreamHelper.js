'use strict';

var utils = require('../utils');
var ConvertWorker = require('./ConvertWorker');
var GenericWorker = require('./GenericWorker');
var base64 = require('../base64');
var NodejsStreamOutputAdapter = require('../nodejs/NodejsStreamOutputAdapter');

/**
 * Apply the final transformation of the data. If the user wants a Blob for
 * example, it's easier to work with an U8intArray and finally do the
 * ArrayBuffer/Blob conversion.
 * @param {String} type the name of the final type
 * @param {String|Uint8Array|Buffer} content the content to transform
 * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the content in the right format.
 */
function transformZipOutput(type, content) {
    switch(type) {
        case "blob" :
            return utils.newBlob(utils.transformTo("arraybuffer", content), "application/zip");
        case "base64" :
            return base64.encode(content);
        default :
            return utils.transformTo(type, content);
    }
}

/**
 * Concatenate an array of data of the given type.
 * @param {String} type the type of the data in the given array.
 * @param {Array} dataArray the array containing the data chunks to concatenate
 * @return {String|Uint8Array|Buffer} the concatenated data
 * @throws Error if the asked type is unsupported
 */
function concat (type, dataArray) {
    var i, index = 0, res = null, totalLength = 0;
    for(i = 0; i < dataArray.length; i++) {
        totalLength += dataArray[i].length;
    }
    switch(type) {
        case "string":
            return dataArray.join("");
        case "uint8array":
            res = new Uint8Array(totalLength);
            for(i = 0; i < dataArray.length; i++) {
                res.set(dataArray[i], index);
                index += dataArray[i].length;
            }
            return res;
        case "nodebuffer":
            return Buffer.concat(dataArray);
        default:
            throw new Error("concat : unsupported type '"  + type + "'");
    }
}

/**
 * Listen a StreamHelper, accumulate its content and concatenate it into a
 * complete block.
 * @param {StreamHelper} helper the helper to use.
 * @param {Function} callback the completion callback. Called with two args :
 * - the error if any, null otherwise
 * - the data if no error, null otherwise
 * @param {Function} updateCallback a callback called on each update. Called
 * with one arg :
 * - the metadata linked to the update received.
 */
function accumulate(helper, callback, updateCallback) {
    var dataArray = [];
    var chunkType = helper._internalType, resultType = helper._outputType;
    helper
    .on('data', function (data, meta) {
        dataArray.push(data);
        if(updateCallback) {
            updateCallback(meta);
        }
    })
    .on('error', function(err) {
        dataArray = [];
        callback(err, null);
    })
    .on('end', function (){
        try {
            var result = transformZipOutput(resultType, concat(chunkType, dataArray));
            utils.delay(callback, [null, result]);
        } catch (e) {
            utils.delay(callback, [e, null]);
        }
        dataArray = [];
    })
    .resume();
}

/**
 * Resolve synchronously a worker.
 * @param {Worker} worker the worker to process.
 * @return {Array} an array of the data generated by the worker
 * @throws Error an error if the worker fails or if the worker is async
 */
function readSyncWorker(worker) {

    if (!worker.supportSync()) {
        throw new Error("Can't resolve this synchronously because at least one worker is asynchronous.");
    }

    var dataArray = [], error = null, ended = false;
    worker
    .on('data', function (chunk) {
        dataArray.push(chunk.data);
    })
    .on('error', function(err) {
        error = err;
        ended = true;
    })
    .on('end', function (){
        ended = true;
    })
    .resume(true);

    if(error) {
        throw error;
    }
    if(!ended) {
        worker.writeError();
        // Zalgo was released !
        throw new Error("bug in readSyncWorker : async operation");
    }


    return dataArray;
}

/**
 * An helper to easily use workers outside of JSZip.
 * @constructor
 * @param {Worker} worker the worker to wrap
 * @param {String} outputType the type of data expected by the use
 */
function StreamHelper(worker, outputType) {
    var internalType = outputType;
    switch(outputType) {
        case "blob":
        case "arraybuffer":
            internalType = "uint8array";
        break;
        case "base64":
            internalType = "string";
        break;
    }

    try {
        // the type used internally
        this._internalType = internalType;
        // the type used to output results
        this._outputType = outputType;
        utils.checkSupport(internalType);
        this._worker = worker.pipe(new ConvertWorker(internalType));
    } catch(e) {
        this._worker = new GenericWorker().error(e);
    }
}

StreamHelper.prototype = {
    /**
     * Resolve the worker synchronously.
     * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the result
     * @throws Error if something went wrong
     */
    _resolveSync : function () {
        var dataArray = readSyncWorker(this._worker);
        var content = concat(this._internalType, dataArray);
        return transformZipOutput(this._outputType, content);
    },
    /**
     * Listen a StreamHelper, accumulate its content and concatenate it into a
     * complete block.
     * @param {Function} cb the completion callback. Called with two args :
     * - the error if any, null otherwise
     * - the data if no error, null otherwise
     * @param {Function} updateCb a callback called on each update. Called
     * with one arg :
     * - the metadata linked to the update received.
     */
    accumulate : function (cb, updateCb) {
        accumulate(this, cb, updateCb);
    },
    /**
     * Add a listener on an event triggered on a stream.
     * @param {String} evt the name of the event
     * @param {Function} fn the listener
     * @return {StreamHelper} the current helper.
     */
    on : function (evt, fn) {
        var self = this;

        if(evt === "data") {
            this._worker.on(evt, function (chunk) {
                fn.call(self, chunk.data, chunk.meta);
            });
        } else {
            this._worker.on(evt, function () {
                utils.delay(fn, arguments, self);
            });
        }
        return this;
    },
    /**
     * Resume the flow of chunks.
     * @return {StreamHelper} the current helper.
     */
    resume : function () {
        utils.delay(this._worker.resume, [false], this._worker);
        return this;
    },
    /**
     * Pause the flow of chunks.
     * @return {StreamHelper} the current helper.
     */
    pause : function () {
        this._worker.pause();
        return this;
    },
    /**
     * Return a nodejs stream for this helper.
     * @return {NodejsStreamOutputAdapter} the nodejs stream.
     */
    asNodejsStream : function () {
        return new NodejsStreamOutputAdapter(this, {
            objectMode : this._outputType !== "nodebuffer"
        });
    }
};


module.exports = StreamHelper;
